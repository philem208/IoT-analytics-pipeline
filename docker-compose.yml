version: '3'
services:
# ZOOKEEPER
  zookeeper:
    image: wurstmeister/zookeeper
    expose:
      - "2181"
    networks:
      - data_service

#  Redis      
  redis:
    image: bitnami/redis:latest
    ports:
      - 6379:6379
    networks:
      - data_hub
      
  emqx:
    image: emqx/emqx:4.2.7
    hostname: emqx
    restart: always
    ports:
      - "1883:1883"
      - "8083:8083"
      - "8084:8084"
      - "8883:8883"
      - "18083:18083"
    networks:
      - data_hub 

 # kafka-mqtt:
 #   image: confluentinc/cp-kafka-mqtt:latest
 #   restart: always
 #   depends_on:
 #     - kafka1
 #     - kafka2
 #     - kafka3
 #   environment:
 #     KAFKA_MQTT_BOOTSTRAP_SERVERS: INSIDE://kafka1:19091
 #     KAFKA_MQTT_LISTENERS: emqx:1883
 #     KAFKA_MQTT_TOPIC_REGEX_LIST: mqtt:.*
 #   networks:
 #     - data_hub
 #     - data_service
      
# mqtt2kafka
  mqtt2kafka:
    image: marmaechler/mqtt2kafkabridge:latest
    hostname: mqtt2kafka
    depends_on:
      - kafka1
      - emqx
    restart: always
    environment:
      KAFKA_BROKER_HOST: kafka1:19091
      MQTT_BROKER_HOST: emqx:1883
      CLIENT_ID: MQTT2Kafka
      MQTT_TOPIC_FILTER: LENZDRGB611
    volumes:
      - ./volumes/mqtt2kafkabridge/logs:/opt/mqtt2kafkabridge/logs
    networks:
      - data_hub
      - data_service

# KAFKA 1
  kafka1:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    restart: always
    hostname: kafka1
    expose:
      - "9091"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB610:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka1:19091,OUTSIDE://localhost:9091
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka1:19091,OUTSIDE://localhost:9091
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data_service
    volumes:
      - ./volumes/kafka1/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"
# KAFKA 2
  kafka2:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    restart: always
    hostname: kafka2
    expose:
      - "9092"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB610:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka2:19092,OUTSIDE://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka2:19092,OUTSIDE://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data_service
    volumes:
      - ./volumes/kafka2/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"
# KAFKA 3
  kafka3:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    restart: always
    hostname: kafka3
    expose:
      - "9093"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB610:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka3:19093,OUTSIDE://localhost:9093
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka3:19093,OUTSIDE://localhost:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data_service
    volumes:
      - ./volumes/kafka3/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"
      
  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    restart: always
    ports:
      - "9000:9000" 
    environment:
      KAFKA_BROKERCONNECT: "kafka1:19091"
    networks:
      - data_service
    depends_on:
      - kafka1
      - kafka2
      - kafka3
 
  elasticsearch:
    hostname: elasticsearch
    build:
      context: volumes/elasticsearch/
    volumes:
      - type: bind
        source: ./volumes/elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    expose: 
      - "9200"
      - "9300"
    environment:
      ES_JAVA_OPTS: "-Xmx512m -Xms512m"
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - analytics

  logstash:
    hostname: logstash
    build:
      context: volumes/logstash/
    volumes:
      - type: bind
        source: ./volumes/logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./volumes/logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    expose:
      - "5044"
      - "5000/tcp"
      - "5000/udp"
      - "9600"
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms512m"
    networks:
      - data_service
      - analytics
    depends_on:
      - elasticsearch
      - kafka1
      - kafka2
      - kafka3


  kibana:
    hostname: kibana
    build:
      context: volumes/kibana/
    volumes:
      - type: bind
        source: ./volumes/kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    networks:
      - analytics
    depends_on:
      - elasticsearch


      
volumes:
  elasticsearch:
    
networks:
  data_hub:
    driver: bridge
  data_service:
    driver: bridge
  analytics:
    driver: bridge

    
