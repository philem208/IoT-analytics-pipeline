version: '3'
services:
# ZOOKEEPER
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181"
    networks:
      - data_service
      
# HiveMQ
  hivemq:
    image: hivemq/hivemq-ce
    hostname: hivemq
    ports: 
      - "1883:1883"
      - "8080:8080"
      - "8000:8000"
    networks:
      - data_hub

# mqtt2kafka
  mqtt2kafka:
    image: marmaechler/mqtt2kafkabridge:latest
    hostname: mqtt2kafka
    depends_on:
      - kafka1
      - hivemq
    restart: always
    environment:
      KAFKA_BROKER_HOST: kafka1:19091
      MQTT_BROKER_HOST: hivemq:1883
    volumes:
      - ./data/mqtt2kafkabridge/logs:/opt/mqtt2kafkabridge/logs
    networks:
      - data_hub
      - data_service

# KAFKA 1
  kafka1:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    hostname: kafka1
    expose:
      - "9091"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB610:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka1:19091,OUTSIDE://localhost:9091
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka1:19091,OUTSIDE://localhost:9091
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data_service
    volumes:
      - ./data/kafka1/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"
# KAFKA 2
  kafka2:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    hostname: kafka2
    expose:
      - "9092"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB611:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka2:19092,OUTSIDE://localhost:9092
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka2:19092,OUTSIDE://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data_service
    volumes:
      - ./data/kafka2/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"
# KAFKA 3
  kafka3:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    hostname: kafka3
    expose:
      - "9093"
    environment:
      KAFKA_CREATE_TOPICS: "LENZDRGB612:1:1" # topic:partition:replicas
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka3:19093,OUTSIDE://localhost:9093
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka3:19093,OUTSIDE://localhost:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_BROKER_ID: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data_service
    volumes:
      - ./data/kafka3/data:/var/lib/kafka/data
    depends_on:
      - "zookeeper"
    links:
      - "zookeeper"
      
  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9002:9002" 
    environment:
      KAFKA_BROKERCONNECT: "kafka1:19091"
    networks:
      - data_service
    depends_on:
      - kafka1
      - kafka2
      - kafka3
 
  elasticsearch:
    hostname: elasticsearch
    build:
      context: data/elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./data/elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    expose: 
      - "9200"
      - "9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - analytics

  logstash:
    hostname: logstash
    build:
      context: data/logstash/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./data/logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./data/logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    expose:
      - "5044"
      - "5000/tcp"
      - "5000/udp"
      - "9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - data_service
      - analytics
    depends_on:
      - elasticsearch

  kibana:
    hostname: kibana
    build:
      context: data/kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./data/kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    networks:
      - analytics
    depends_on:
      - elasticsearch

volumes:
  elasticsearch:
  
networks:
  data_service:
    driver: bridge
  analytics:
    driver: bridge
  data_hub:
    driver: bridge

    
